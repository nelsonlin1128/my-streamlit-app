# app.py
import streamlit as st
from PIL import Image
import torch
from diffusers import StableDiffusionImg2ImgPipeline, UNet2DConditionModel

# â€”â€” Streamlit é é¢è¨­å®š â€”â€”
st.set_page_config(page_title="å¤šé¢¨æ ¼ Img2Img Demo", layout="wide")
st.title("ğŸ¨ å¤šé¢¨æ ¼è—è¡“é¢¨æ ¼è½‰æ›")

# â€”â€” å´é‚Šæ¬„ï¼šåƒæ•¸é¸æ“‡ â€”â€”
st.sidebar.header("åƒæ•¸è¨­å®š")
style = st.sidebar.selectbox("é¸æ“‡é¢¨æ ¼", ["jojo", "cyberpunk2077", "ghibli"] )
strength = st.sidebar.slider("é¢¨æ ¼å¼·åº¦ (strength)", 0.0, 1.0, 0.7)
guidance = st.sidebar.slider("å¼•å°å¼·åº¦ (guidance scale)", 1.0, 12.0, 7.5)
steps = st.sidebar.slider("æ¨ç†æ­¥æ•¸ (inference steps)", 10, 100, 50)

# â€”â€” ä¸Šå‚³å…§å®¹åœ– â€”â€”
uploaded = st.file_uploader("ä¸Šå‚³å…§å®¹åœ– (512Ã—512)", type=["jpg","png"])
if not uploaded:
    st.warning("è«‹å…ˆä¸Šå‚³ä¸€å¼µåœ–ç‰‡ï¼")
    st.stop()
init_image = Image.open(uploaded).convert("RGB").resize((512,512))
st.image(init_image, caption="åŸåœ–", use_column_width=True)

# â€”â€” å¿«å–ç®¡ç·šè¼‰å…¥ â€”â€”
@st.cache_resource
def load_pipeline():
    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16
    ).to("cuda")
    return pipe

pipe = load_pipeline()
pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))

# â€”â€” é¢¨æ ¼èˆ‡ checkpoint æ­¥æ•¸å°æ‡‰ â€”â€”
ckpt_map = {"jojo": 35000, "cyberpunk2077": 35000, "ghibli": 35000}
ckpt_step = ckpt_map.get(style, 15000)
ckpt_dir = f"outputs/checkpoint-{ckpt_step}"

# â€”â€” å¿«å– UNet è¼‰å…¥ â€”â€”
@st.cache_resource
def load_unet(ckpt_dir):
    new_unet = UNet2DConditionModel.from_pretrained(
        ckpt_dir, torch_dtype=torch.float16
    ).to("cuda")
    return new_unet

pipe.unet = load_unet(ckpt_dir)

# â€”â€” ç”ŸæˆæŒ‰éˆ•èˆ‡æ¨ç† â€”â€”
if st.sidebar.button("é–‹å§‹ç”Ÿæˆ"):
    with st.spinner("ç”Ÿæˆä¸­ï¼Œè«‹ç¨å€™â€¦"):
        generator = torch.Generator(device="cuda").manual_seed(42)
        prompt = f"a portrait in the style of {style}"
        out = pipe(
            prompt=prompt,
            image=init_image,
            strength=strength,
            guidance_scale=guidance,
            num_inference_steps=steps,
            generator=generator
        ).images[0]
        st.image(out, caption=f"{style} é¢¨æ ¼åŒ–çµæœ (checkpoint {ckpt_step})", use_column_width=True)
